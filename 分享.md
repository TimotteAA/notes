## Docker

#### 为啥要Docker

早期传统的软件开发流程：

* 开发团队：在开发环境中完成开发，单元测试通过后，提交到仓库
* 运维人员：把开发的代码打包，上传到测试环境上去
* 测试：开测，测完通过；运维再上传到生成环境中，在进行测试

![image-20240114082240271](https://typora-1316630864.cos.ap-shanghai.myqcloud.com/undefinedimage-20240114082240271.png)

**最大的问题**：后端服务的生产环境部署，在不同的机器上部署redis、mysql、es.....

docker带来了一种应用程序级别的环境部署方案，从开发->测试->生产环境的统一部署。



#### docker的架构

下面的图片完整的描述了Docker的架构：
![image-20240107085059716](https://typora-1316630864.cos.ap-shanghai.myqcloud.com/undefinedimage-20240107085059716.png)



###### Dockerfile

## dockerfile

dockerfile用于构建镜像

1. 编写dockerfile文件
2. build 构建镜像
3. run 运行镜像
4. push 发送镜像，供别人使用



### dockerfile文件的编写

1. 每个内置关键字大写
2. 从上到下编写指令
3. 每一层都是一层commit
4. #写注释

下图解释了dockerfile各个命令的阶段：
![image-20240107141550661](https://typora-1316630864.cos.ap-shanghai.myqcloud.com/undefinedimage-20240107141550661.png)



```BASH
FROM             # 基础镜像，一切从这开始
MAINTAINER       # 维护者信息
WORKDIR          # 镜像的工作目录，后续cmd，run的命令都在此命令下，包含exec -it进入容器内部

RUN              # 构建时需要执行的命令
ADD              # 往里面加东西
COPY             # 拷贝文件到镜像中


VOLUME           # 挂载卷
EXPOSE           # 指定容器暴露端口
CMD              # 容器运行时的指令，但只有最后一个会生效
ENTRYPOINT       # 和CMD一致，可以追加命令、参数
ENV              # 设置环境变量

```



下面写了个一个ubuntu的镜像：

```BASH
FROM ubuntu:latest
LABEL author=xxx
LABEL email=xxx@gmail.com
# 环境变量
ENV USERDIR /usr/local
# 工作目录
WORKDIR $USERDIR

# 更新软件包列表
RUN apt-get update

# 安装 vim
RUN apt-get install -y vim
RUN apt-ge install net-tools

EXPOSE 80

CMD echo $USERDIR
CMD ehco "----end----"
# 运行容器后直接进入teminal
CMD /bin/bash

# 构建
docker build -t 文件 -t tag . # .不能漏了！

docker run -it 2c6b85f44230 
root@e7d64f093a0a:/usr/local # 可以看到，一进去就在 /usr/local下
```

可以使用docker history 查看某个镜像的构建历史：

```bash
docker history 镜像id

docker history c48d6d7dd0
IMAGE          CREATED        CREATED BY                                      SIZE      COMMENT
c48d6d7dd03a   2 months ago   nginx -g daemon off;                            3.52kB    test
295c7be07902   4 years ago    /bin/sh -c #(nop)  CMD ["nginx" "-g" "daemon…   0B        
<missing>      4 years ago    /bin/sh -c #(nop)  STOPSIGNAL SIGTERM           0B        
<missing>      4 years ago    /bin/sh -c #(nop)  EXPOSE 80                    0B        
<missing>      4 years ago    /bin/sh -c ln -sf /dev/stdout /var/log/nginx…   22B       
<missing>      4 years ago    /bin/sh -c set -x  && apt-get update  && apt…   53.8MB    
<missing>      4 years ago    /bin/sh -c #(nop)  ENV NJS_VERSION=1.14.2.0.…   0B        
<missing>      4 years ago    /bin/sh -c #(nop)  ENV NGINX_VERSION=1.14.2-…   0B        
<missing>      4 years ago    /bin/sh -c #(nop)  LABEL maintainer=NGINX Do…   0B        
<missing>      4 years ago    /bin/sh -c #(nop)  CMD ["bash"]                 0B        
<missing>      4 years ago    /bin/sh -c #(nop) ADD file:4fc310c0cb879c876…   55.3MB  
```

### 

## k8s

k8s提供了一种生产环境下的**自动化**容器编排：

![image-20240120193044769](https://typora-1316630864.cos.ap-shanghai.myqcloud.com/undefinedimage-20240120193044769.png)

#### 资源和对象

k8s中，一切皆资源（用yaml描述），不同的资源，有不同的yaml对象来描述。

**换种理解，资源是类，对象是资源的实例**。

对象的创建、调度，都是通过api server的http restful接口来实现的。



##### 规约和状态

规约（spec）描述了对象的期望状态，以及一些基本对象。‘

状态（status），表示对象的实际状态，由k8s维护，通过控制器来对对象进行管理，让对象的实际状态尽可能地与期望状态靠拢。

##### 资源的分类

资源的类型可以分成：集群、命名空间、元空间

![image-20240121090601798](https://typora-1316630864.cos.ap-shanghai.myqcloud.com/undefinedimage-20240121090601798.png)

对于资源的划分，主要是为了区分资源能够跨集群、空间的共享

**元数据**

1. hpa：根据机器情况下进行缩扩容：预定指标、自定义rest api情况

2. PodTemplate：创建pod的模板
3. LimitRange：对象所用cpu、内存的限制

**集群**

1. namespace命名空间
2. Node节点资源（服务器），k8s只是管理node上的资源
3. ClusterRole、ClusterRoleBinding：rbac鉴权用的

**命名空间级的资源**

1. pod：Pod 是 Kubernetes 中的基本工作单元，代表着在集群中运行的一个或多个容器的组合。

   每个 Pod 都有自己的 IP 地址，但这个地址在 Pod 重建时会改变。

   Pod 可以承载应用程序的实例，是部署容器化应用的基本单位。

   <img src="https://typora-1316630864.cos.ap-shanghai.myqcloud.com/undefinedimage-20240121125439306.png" alt="image-20240121125439306" style="zoom:150%;" />

​	pod中的pause容器，提供了容器的文件共享、网络共享的功能。

​	一个pod的yaml描述：

```YAML
# apiVersion
apiVersion: v1
# 定义的k8s资源类型
kind: Pod
# 资源的元数据
metadata:
  # 名称
  name: "nginx"
  # 命名空间
  namespace: default
  # 标签，用于service、deployment的匹配
  labels:
    app: "MYAPP"
# pod的期望规格
spec:
  # pod里的容器
  containers:
  # 容器名称，随便取
  - name: test-nginx
    # 镜像名称
    image: "nginx:latest"
    imagePullPolicy: IfNotPresent # 如果本地不存在，则去远程repo拉
    # 对资源的一些配置
    resources:
      # 最大
      limits:
        # 1000m是一个核心
        cpu: 200m
        memory: 500Mi
      # 最低
      requests:
        cpu: 100m
        memory: 200Mi
    # 环境变量
    env:
    - name: DB_HOST
      value: "hahahahaha"
    # 定义容器的端口
    ports:
      # 容器暴露的端口
    - containerPort:  80
      # 名称
      name:  http
      # 端口用的协议类型
      protocol: TCP
  # pod的重启策略
  # OnFailure
  restartPolicy: OnFailure # 失败才重启
```





2. pod的控制器：在pod基础上添加了pod副本数的管理。

   1. 比如ReplicaSet，动态更新pod的副本数

      ![Image description](https://typora-1316630864.cos.ap-shanghai.myqcloud.com/undefinedeHQ3cXFwYi5wbmc)

   2. deployment，在ReplicaSet上再封装，除了动态更新pod的副本数，还支持滚动升级与回滚（更新了描述pod的yaml，会创建新的rs）、暂停与恢复。deployment可以定义rs

​		![image-20240121130758147](https://typora-1316630864.cos.ap-shanghai.myqcloud.com/undefinedimage-20240121130758147.png)

​	当你更新了一个 Deployment（比如，改变了容器的镜像版本）时，Kubernetes 会创建一个新的 ReplicaSet（ReplicaSet2）来开始部署新版本的 Pod。

​	新的 ReplicaSet 会逐渐增加新版本的 Pod 副本数量，同时旧的 ReplicaSet（ReplicaSet1）会逐渐减少旧版本的 Pod 副本数量。		

​	这个过程是滚动更新，意味着新旧版本的 Pod 会在一段时间内共存，以确保服务的可用性。

​	当新的 ReplicaSet 的 Pod 副本数达到了 Deployment 指定的期望副本数量，而旧的 ReplicaSet 的副本数降为零时，更新就完成了。







###### 服务发现

1. service命名空间的网络访问

![image-20240121131631611](https://typora-1316630864.cos.ap-shanghai.myqcloud.com/undefinedimage-20240121131631611.png)

service描述了集群内部的网路访问




![image-20240121143826136](https://typora-1316630864.cos.ap-shanghai.myqcloud.com/undefinedimage-20240121143826136.png)

当创建好service后，k8s内部会自动创建一个endpoint，其中会记录着service的selector匹配的pod的ip地址、目标端口号。这样子pod就能通过endpoint去访问另一个pod。

详细步骤：

1. **创建 Service**：定义一个 Service，并为其指定一个选择器，该选择器匹配一组 Pod 的标签。
2. **选择器匹配 Pod**：Kubernetes 根据 Service 定义的选择器找到所有带有匹配标签的 Pod。
3. **自动创建 Endpoints**：Kubernetes 为每个匹配的 Pod 创建一个 Endpoint，并记录 Pod 的 IP 地址和端口号。Endpoints 资源的名称通常与 Service 的名称相同。
4. **服务发现**：当集群内的其他 Pod 需要与这些 Pod 通信时，它们会使用 Service 的名称。DNS 解析会自动解析为 Service 的虚拟 IP（Cluster IP），实际的网络流量将由 Service 根据 Endpoints 资源进行路由到具体的 Pod。
5. **负载均衡**：如果 Service 定义了多个 Pod，来自 Service 的请求将会在所有可用的 Endpoint 之间负载均衡。
6. **动态更新**：如果后续有新的 Pod 被创建或现有的 Pod 被删除，并且它们符合 Service 的选择器，Endpoints 资源会自动更新以反映这些变化。



yaml：

```YAML
# https://kubernetes.io/docs/concepts/services-networking/service/
apiVersion: v1
kind: Service
metadata:
  # 元数据
  name: myjob
  namespace: default
spec:
  # 匹配哪些pod，去代理请求
  # k,v匹配的方式
  selector:
    app: myjob
  # type支持：
  # NodePort，随机启动一个端口映射：30000->32727，映射到port，注意该端口直接绑定到host机上。
  # 
  type: ClusterIP
  # 端口映射
  ports:
  - name: myjob
    protocol: TCP
    # service的端口，集群内网的端口
    port: 80
    # 转发到目标pod的哪个端口
    targetPort: 5000
    nodePort: 30001


```



### 集群内布service访问集群外部服务

实现方式：

创建service时，不指定selector，手动创建endpoint

```bash
apiVersion: v1
kind: Endpoint
metadata:
  # 元数据
  name: myjob
  namespace: default
  labels: 
  	app: nginx
subnets:
- addresses:
	-ip: xxxx # service代理ip
	ports: # 和service一致
	- name: http
	  protocol: TCP
	  port: 80
```



### 基于域名的访问方式

Service也提供了基于域名的访问方式：

```YAML
apiVersion: v1
kind: Service
metadata:
  name: baidu-external-domain
  namespace: default
spec:
  type: ExternalName
  externalName: www.baidu.com
```

在集群内布的pod，可以直接通过 baidu-external-domain的方式去访问。



## gitlab

### ci：持续集成，cd：持续交付/持续部署

### 持续集成 （CI）

持续合并开发人员正在开发编写的所有代码的一种做法。通常一天内进行多次合并和提交代码，从存储库或生产环境中进行构建和自动化测试，以确保没有集成问题并及早发现任何问题。

**开发人员提交代码的时候一般先在本地测试验证，只要开发人员提交代码到版本控制系统就会触发一条提交流水线，对本次提交进行验证。**



对于cd，一般有两种解释：

### 持续交付 （CD）

[持续交付](https://continuousdelivery.com/)是超越持续集成的一步。不仅会在推送到代码库的每次代码更改时都进行构建和测试，而且，作为附加步骤，即使部署是手动触发的，它也可以连续部署。此方法可确保自动检查代码，但需要人工干预才能从策略上手动触发更改的部署。

### 持续部署 (CD)

通常可以通过将更改自动推送到发布系统来随时将软件发布到生产环境中。持续部署 会更进一步，并自动将更改推送到生产中。类似于持续交付，[持续部署](https://www.airpair.com/continuous-deployment/posts/continuous-deployment-for-practical-people)也是超越持续集成的又一步。不同之处在于，您无需将其手动部署，而是将其设置为自动部署。部署您的应用程序完全不需要人工干预。



## gitlab cicd

gitlab cicd架构可以由下图说明：

![image-20240114082726630](https://typora-1316630864.cos.ap-shanghai.myqcloud.com/undefinedimage-20240114082726630.png)

1. 一个gitlab server，包含了代码仓库
2. runner server，在开发人员提交到代码仓库后，根据 .gitlab-ci.yml 去匹配runner干活
3. 代码仓库中的 .gitlab-ci.yml 文件，指定了整套流水线的一个个stage、干活的runner



```bash
# 安装gitlab社区版需要的组件
sudo dnf install -y curl policycoreutils openssh-server perl

# 添加gitlab repo
curl https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bash

# 安装gitlab
sudo EXTERNAL_URL="http://yourdomain.com" dnf install -y gitlab-ce

## 等待一坨时间
cd /ect/gitlab
cat initial_root_password # 这里包含了初始密码
```



#### gitlab runner

类型：

1. project，项目类型，只针对单独的project
2. group，一个group包含多个project，所有的项目都会运行
3. specific 项目类型，针对特定的项目作业

状态

1. locked：锁定状态，无法运行项目作业
2. paused：暂停状态



首先是shared runner：

![image-20240114104153572](https://typora-1316630864.cos.ap-shanghai.myqcloud.com/undefinedimage-20240114104153572.png)

然后创建一个group，创建项目，可以看到一个project runner：

![image-20240114105018370](https://typora-1316630864.cos.ap-shanghai.myqcloud.com/undefinedimage-20240114105018370.png)



安装gitlab runner，这里采用docker的方式：

```BASH
docker pull gitlab/gitlab-runner

docker run -d --name gitlab-runner --restart always \
  -v /var/run/docker.sock:/var/run/docker.sock \
  -v /etc/gitlab-runner \
  gitlab/gitlab-runner:latest

# gitlab runner的配置卷匿名即可

# 注册runner
docker exec -it gitlab-runner gitlab-runner register
Runtime platform                                    arch=amd64 os=linux pid=48 revision=102c81ba version=16.7.0
Running in system-mode.                            
                                                   
Enter the GitLab instance URL (for example, https://gitlab.com/):
# 输入gitlab url
https://xxx

Enter the registration token:
# gitlab里可以拿到
Enter a description for the runner:

[80e6ad02bfaa]: first shared runner


Enter tags for the runner (comma-separated):
tag 后面有用
deploy,build
Enter optional maintenance note for the runner:

WARNING: Support for registration tokens and runner parameters in the 'register' command has been deprecated in GitLab Runner 15.6 and will be replaced with support for authentication tokens. For more information, see https://docs.gitlab.com/ee/ci/runners/new_creation_workflow 
Registering runner... succeeded                     runner=FnNtNDRG

# runner执行器的类型，常用custom、docker、kubetnetes
Enter an executor: custom, docker-windows, parallels, virtualbox, docker-autoscaler, docker+machine, instance, kubernetes, docker, shell, ssh:
shell
Runner registered successfully. Feel free to start it, but if it's running already the config should be automatically reloaded!
 
Configuration (with the authentication token) was saved in "/etc/gitlab-runner/config.toml" 



```

结果：
![image-20240114114919985](https://typora-1316630864.cos.ap-shanghai.myqcloud.com/undefinedimage-20240114114919985.png)



在项目根目录中，添加下面的.gitlab-ci.yml文件：

```yml
# 定义stage
stages:
  - build
  - deploy
 
# 定义一个个的job，job是gitlab管道的一个个核心任务
build:
  stage: build
  tags:
    - build
  only:
    - master
  script:
    - echo "npm install"


deploy:
  stage: deploy
  tags:
    - deploy
  only:
    - master
  script:
    - echo "hello deploy"
```



结果：

![image-20240114115915315](https://typora-1316630864.cos.ap-shanghai.myqcloud.com/undefinedimage-20240114115915315.png)

## 集成gitlab cicd和k8s

[helm](https://helm.sh/)，一个和k8s交互的包管理工具。


是的，你的理解基本准确。在 CI/CD 流程中构建镜像成功后，通常会将镜像推送到镜像仓库（可以是私有仓库，也可以是公共仓库，如 Docker Hub），然后通过 Helm 和 Kubernetes 交互来更新 Kubernetes 集群中的 Pod。以下是整个过程的详细步骤：

1. **构建镜像**：
   - 在 CI/CD 流程中（如使用 GitLab CI/CD），构建 Docker 镜像。
   - 镜像通常会被打上标签，这可以是提交的哈希值、分支名、标签名或其他唯一标识符。
2. **推送镜像到仓库**：
   - 将构建好的镜像推送到 Docker 镜像仓库。这个仓库可以是 Docker Hub、Harbor、Amazon ECR、Google GCR、GitLab Container Registry 等。
   - 如果是私有仓库，需要确保 Kubernetes 集群能够访问这个仓库。
3. **配置 Kubernetes 访问私有仓库**：
   - 如果使用私有镜像仓库，需要在 Kubernetes 集群中配置镜像拉取凭据。
   - 这通常通过创建一个 Kubernetes Secret 来实现，然后在 Pod 的定义中引用该 Secret 以拉取私有镜像。
4. **Helm 更新 Kubernetes 资源**：
   - 在 Helm chart 的配置中（通常是 `values.yaml` 文件），指定新的镜像标签。
   - 通过 Helm 命令（如 `helm upgrade`）更新 Kubernetes 集群上的应用。这个命令会使 Kubernetes 使用新的镜像创建 Pod。
5. **Pod 更新**：
   - Kubernetes 根据更新后的 Helm chart 创建新的 Pod 实例，如果配置了滚动更新策略，这会逐步替换旧的 Pod 实例。
   - Kubernetes 会从指定的镜像仓库拉取新的镜像，并在集群中启动新的 Pod。
6. **验证部署**：
   - 在 CI/CD 流程中可以添加步骤以验证新部署的应用是否运行正常。

通过这个过程，CI/CD 系统可以自动化地将构建的镜像部署到 Kubernetes 集群中，而 Helm 用于简化和管理这个部署过程。